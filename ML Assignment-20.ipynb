{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd581241",
   "metadata": {},
   "source": [
    "1. What is the underlying concept of Support Vector Machines?\n",
    "\n",
    "2. What is the concept of a support vector?\n",
    "\n",
    "3. When using SVMs, why is it necessary to scale the inputs?\n",
    "\n",
    "4. When an SVM classifier classifies a case, can it output a confidence score? What about a percentage chance?\n",
    "\n",
    "5. Should you train a model on a training set with millions of instances and hundreds of features using the primal or dual form of the SVM problem?\n",
    "\n",
    "6. Let&#39;s say you&#39;ve used an RBF kernel to train an SVM classifier, but it appears to underfit the training collection. Is it better to raise or lower (gamma)? What about the letter C?\n",
    "\n",
    "7. To solve the soft margin linear SVM classifier problem with an off-the-shelf QP solver, how should the QP parameters (H, f, A, and b) be set?\n",
    "\n",
    "8. On a linearly separable dataset, train a LinearSVC. Then, using the same dataset, train an SVC and an SGDClassifier. See if you can get them to make a model that is similar to yours.\n",
    "\n",
    "9. On the MNIST dataset, train an SVM classifier. You&#39;ll need to use one-versus-the-rest to assign all 10 digits because SVM classifiers are binary classifiers. To accelerate up the process, you might wantto tune the hyperparameters using small validation sets. What level of precision can you achieve?\n",
    "\n",
    "10. On the California housing dataset, train an SVM regressor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7a5119",
   "metadata": {},
   "source": [
    "# Solution:-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b733ee7b",
   "metadata": {},
   "source": [
    "1. What is the underlying concept of Support Vector Machines?\n",
    "\n",
    "The underlying concept of Support Vector Machines (SVMs) is to find an optimal hyperplane that maximally separates different classes in a dataset. It is a supervised machine learning algorithm used for both classification and regression tasks.\n",
    "\n",
    "2. What is the concept of a support vector?\n",
    "\n",
    "Support vectors are data points from the training set that lie closest to the decision boundary (hyperplane) of an SVM classifier. These data points have the most influence on determining the position and orientation of the decision \n",
    "boundary.\n",
    "\n",
    "3. When using SVMs, why is it necessary to scale the inputs?\n",
    "\n",
    "Scaling the inputs is necessary when using SVMs because SVMs are sensitive to the scale of the features. If the features have different scales, it can lead to biased results where some features dominate the learning process. By scaling the inputs, all features are brought to a similar scale, ensuring fair representation and preventing undue influence of certain features.\n",
    "\n",
    "4. When an SVM classifier classifies a case, can it output a confidence score? What about a percentage chance?\n",
    "\n",
    "Yes, an SVM classifier can output a confidence score, which indicates the classifier's level of certainty in its prediction. The confidence score is typically obtained as the distance between the data point and the decision boundary. However, SVMs do not provide a direct probability estimation or percentage chance. To obtain probability estimates, additional techniques like Platt scaling or cross-validation can be applied.\n",
    "\n",
    "5. Should you train a model on a training set with millions of instances and hundreds of features using the primal or dual form of the SVM problem?\n",
    "\n",
    "When dealing with large datasets, it is generally recommended to use the dual form of the SVM problem instead of the primal form. The dual form is more computationally efficient for datasets with a large number of instances. However, for datasets with a large number of features, the primal form may be more suitable. It is advised to consider the characteristics of the dataset and conduct experiments to determine the most efficient approach.\n",
    "\n",
    "6. Let's say you've used an RBF kernel to train an SVM classifier, but it appears to underfit the training collection. Is it better to raise or lower (gamma)? What about the letter C?\n",
    "\n",
    "When an SVM classifier using an RBF kernel underfits the training data, increasing the value of the gamma parameter may be beneficial. Gamma determines the reach of the kernel and increasing it makes the decision boundary more flexible, potentially improving the model's ability to capture complex patterns. Additionally, decreasing the value of the C parameter, which controls the regularization strength, can also help the model fit the training data better by allowing for more flexibility in the margin.\n",
    "\n",
    "7. To solve the soft margin linear SVM classifier problem with an off-the-shelf QP solver, how should the QP parameters (H, f, A, and b) be set?\n",
    "\n",
    "In the soft margin linear SVM classifier problem, the QP parameters are set as follows:\n",
    "H is the matrix of shape (n_samples, n_samples) defined as the outer product of the training samples' labels (y) multiplied by the dot product of the training samples' feature vectors (X).\n",
    "f is the vector of shape (n_samples, 1) defined as an array of -1's.\n",
    "A is the matrix of shape (n_samples, n_samples) defined as a diagonal matrix with -1's on the main diagonal.\n",
    "b is the vector of shape (n_samples, 1) defined as an array of 0's.\n",
    "\n",
    "8. On a linearly separable dataset, train a LinearSVC. Then, using the same dataset, train an SVC and an SGDClassifier. See if you can get them to make a model that is similar to yours.\n",
    "\n",
    "The solution to this question involves training different classifiers on a linearly separable dataset and comparing their performance. \n",
    "\n",
    "9. On the MNIST dataset, train an SVM classifier. You'll need to use one-versus-the-rest to assign all 10 digits because SVM classifiers are binary classifiers. To accelerate up the process, you might want to tune the hyperparameters using small validation sets. What level of precision can you achieve?\n",
    "\n",
    "Training an SVM classifier on the MNIST dataset using one-versus-the-rest strategy requires preprocessing the dataset, training multiple SVM classifiers, and evaluating their performance. Hyperparameter tuning using validation sets can also be performed to optimize the model's precision. The achieved precision level would depend on the specific implementation, hyperparameter settings, and preprocessing techniques employed.\n",
    "\n",
    "10. On the California housing dataset, train an SVM regressor.\n",
    "\n",
    "Training an SVM regressor on the California housing dataset involves preprocessing the dataset, splitting it into training and test sets, fitting the SVM regressor to the training data, and evaluating its performance on the test data. The specific implementation and hyperparameter settings would determine the quality of the regressor's predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045901bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ade52a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a93c510",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad70f84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10902f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aea47ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c53971",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639a06a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a01365d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349cddc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d393732",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba4beaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370790ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10674b31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f77607",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
